[{"id":0,"href":"/notes/books/","title":"Books","section":"Shantanu's Notesverse","content":" Notes on books that I read # "},{"id":1,"href":"/notes/braindump/","title":"Braindump","section":"Shantanu's Notesverse","content":" Collection of random notes, thoughts, and ideas. # "},{"id":2,"href":"/notes/books/ddia/chapter-1/","title":"Chapter 1: Foundations of Data Systems","section":"Designing Data-Intensive Applications","content":" Foundations of Data Systems # 3 Important Characteristics of Data Systems # Reliability: System should continue to work correctly even in the face of adversity and maintain same perf levels Scalability: As the system grows, there should be reasonable ways to deal with the growth Maintainability: Different people should be able to work on it productively across time Reliability # This can include:\nPerforming expected functions correctly Tolerate user mistakes or unexpected inputs Maintain good enough performance under load Prevent unauthorized access and abuse Types of faults:\nHardware -\u0026gt; Typically mitigated by redundant hardware Software -\u0026gt; Typically mitigated by thinking upfront about design and careful testing Human error -\u0026gt; Typically mitigated by careful design and testing Scalability # This is system\u0026rsquo;s ability to cope with increased load.\nLoad -\u0026gt; Can be described with the help of numbers we can call as load parameters. The parameters would depend on the system architecture. E.g.:\nWeb server -\u0026gt; Number of requests per second Database -\u0026gt; Number of read/write operations per second or read to write ratio Chat Room -\u0026gt; Simultaneously active users Cache -\u0026gt; Hit/miss rate Twitter Example # Tweet post rate -\u0026gt; 4.6K RPS average, 12K RPS peak Home TL View -\u0026gt; 300k RPS average\nOption 1:\nInsert each posted tweet to a global collection. When a user views their TL, fetch all their followee\u0026rsquo;s tweets and merge them. Simple but slow due to all the joins.\nOption 2:\nMaintain a cache for each user\u0026rsquo;s TL. On a tweet post, update TL cache for all followers of tweet poster. This approach is fast on read but can become very expensive for people with large following. E.g. a user with 30 mn followers would mean 30mn writes per tweet.\nFinal Solution used at twitter: Hybrid approach of above 2. For most users, do 2nd option. For users with high number of followers (e.g. celebs), do option 1 (i.e. their tweets get merged into the caches at view time).\nPerformance # Batch processing systems (e.g. Hadoop) care more about throughput while online systems care more about response time.\nLatency -\u0026gt; duration where request is waiting to be handled\nResponse time -\u0026gt; Total time spent in serving a request that a client sees (thus, including latency)\nResponse time is not a single number but a distribution since you\u0026rsquo;d get slightly different response times for every request. A good metric to use while reporting perf data like response time is percentiles, not averages. This is because averages can hide outliers and also don\u0026rsquo;t tell about how many users experienced a given response time.\nMedian (P50), P95, P99 etc are good metrics. High percentiles of response times are also called tail latencies.\nNote: Amazon describes response time requirements for internal services in terms of P99.9, even though it affects only 1 in 1000 requests. Because often those are the users with most data because they\u0026rsquo;ve made most purchases.\nAmazon observes that a 100ms increase in response time for a request reduces sales by 1%. Others report that a 1 second slow down reduces customer satisfaction by 16%.\nNote that trying to satisfy too high tail latencies is also not useful so there should be a balance of ROI.\nQueueing delays are also known as head of line blocking.\nLoad Test -\u0026gt; Should keep generating and sending requests without waiting for previous response to finish, to simulate the behavior of a real system where there could be queueing delays.\nTail latency amplification -\u0026gt; When a user request results in multiple backend calls, even 1 slow call slows down the whole response \u0026amp; there\u0026rsquo;s a high chance of several users experiencing this.\nApproaches for coping with load:\nVertical scaling -\u0026gt; Increase the resources of a single machine Horizontal scaling -\u0026gt; Distribute load across multiple smaller machines. Also called shared-nothing architecture. Good architectures employ a pragmatic mix of both. Elasticity, or automatic scaling, is useful for unpredictable loads.\nMaintainability # 3 Design Principles:\nOperability -\u0026gt; Making life easy for operations Simplicity -\u0026gt; Managing complexity Evolvability -\u0026gt; Making change easy Accidental Complexity -\u0026gt; Complexity is accidental if it is not inherent in the problem that the software solves, but arises only from the implementation. Abstractions can help reduce accidental complexity. High level programming languages are abstractions too.\n"},{"id":3,"href":"/notes/books/ddia/","title":"Designing Data-Intensive Applications","section":"Books","content":" Designing Data-Intensive Applications # Notes on the book by Martin Kleppmann. Click on the chapter links on the sidebar to view the notes.\n"},{"id":4,"href":"/notes/books/ddia/chapter-2/","title":"Chapter 2: Data Models and Query Languages","section":"Designing Data-Intensive Applications","content":"Most applications are built by layering one data model on top of another. Each layer hides the complexity of the layer below it by providing a clean data model.\nRelational model v/s Document model # SQL based on relational model proposed by Edgar Codd in 1970. Data is organized into relations (tables in SQL) where each relation is an unordered collection of tuples (rows in SQL).\nGoal of relational model was to hide the implementation detail behind a cleaner interface.\nOther competing alternatives that came and went -\u0026gt; Network model, Hierarchical model, XML DBs etc.\nBirth of NoSQL # The name NoSQL originated as a catch twitter hashtag for an OSS distributed DB meetup. Retroactively reinterpreted as Not Only SQL.\nDriving forces behind NoSQL:\nGreater scalability Free and OSS preference over commercial DBs More dynamic data models Object Relational Mismatch # A translation layer is required between application code and the DB model. Difference between these models is called impedance mismatch.\nObject Relational Mapping (ORM) frameworks reduce the boilerplate code required for this translation layer, but don\u0026rsquo;t completely hide the complexity.\nExample for options to store a linkedin profile data in DB:\nRelational Save the varying info (education, companies, cities, etc) in separate tables with foreign key references to the users table Save this info in structured data types like XML or JSON within the same row with querying/indexing support Encode as XML or JSON and save in a text field column of same row, but this loses querying etc support, and the app needs to manage/interpret this data Document oriented DBs directly store all the information as a self-contained JSON doc. This reduces impedance mismatch but loses schema enforcement. It also provides better locality of all info of a user in one place. Also good for one to many relationships. Many to one and Many to Many relationships # Many to one relationships (e.g. many people in seattle) don\u0026rsquo;t fit nicely into the document model. In relational DBs, joins are easy but join support is weak in document DBs. And so, in such cases, application code might need to do the joins.\n"}]